# ğŸ”§ LLMä¾›åº”å•†é…ç½®ä¿®æ”¹æŒ‡å—

## ğŸ“ é…ç½®ä¿®æ”¹ä½ç½®

### æ–¹æ³•1ï¼šä¿®æ”¹é…ç½®æ–‡ä»¶ï¼ˆæ¨èï¼‰

#### 1. ä¿®æ”¹ `src/main/resources/application.properties`
```properties
# Graph Database Configuration
graph.database.type=neo4j
graph.database.uri=bolt://localhost:7687
graph.database.username=neo4j
graph.database.password=password

# LLM Configuration - ä¿®æ”¹è¿™é‡Œï¼
openai.api.key=${YOUR_API_KEY:}
openai.api.url=https://your-llm-provider.com/v1/chat/completions
openai.model=your-model-name

# Embedding Configuration - å¦‚æœéœ€è¦ä¿®æ”¹embeddingæœåŠ¡
embedding.api.url=https://your-embedding-provider.com/v1/embeddings
embedding.model=your-embedding-model

# Search Engine Configuration
search.engine.type=simple

# Reasoning Configuration
reasoning.max.depth=3
reasoning.width=3
reasoning.entity.threshold=0.5
reasoning.relation.threshold=0.2
reasoning.temperature=0.0
reasoning.max.tokens=256

# Logging Configuration
logging.level.com.tog.graph=INFO
logging.level.org.neo4j=WARN
```

#### 2. ä¿®æ”¹ `src/main/java/com/tog/graph/config/GraphConfig.java`
```java
public class GraphConfig {
    // ... å…¶ä»–é…ç½® ...
    
    // LLMé…ç½® - ä¿®æ”¹é»˜è®¤å€¼
    private String openaiApiKey;
    private String openaiApiUrl = "https://your-llm-provider.com/v1/chat/completions";  // ä¿®æ”¹è¿™é‡Œ
    private String openaiModel = "your-model-name";  // ä¿®æ”¹è¿™é‡Œ
    
    // åµŒå…¥æœåŠ¡é…ç½® - å¦‚æœéœ€è¦ä¿®æ”¹
    private String embeddingServiceType = "openai";
    private String embeddingApiUrl = "https://your-embedding-provider.com/v1/embeddings";  // ä¿®æ”¹è¿™é‡Œ
    private String embeddingModel = "your-embedding-model";  // ä¿®æ”¹è¿™é‡Œ
    private int embeddingCacheSize = 1000;
    
    // ... getterå’Œsetteræ–¹æ³•ä¿æŒä¸å˜ ...
}
```

### æ–¹æ³•2ï¼šåœ¨æ¼”ç¤ºç¨‹åºä¸­ç›´æ¥ä¿®æ”¹

#### ä¿®æ”¹ `src/main/java/com/tog/graph/demo/GraphReasoningDemo.java`
```java
private static GraphConfig createConfig() {
    GraphConfig config = new GraphConfig();
    
    // ä»ç¯å¢ƒå˜é‡è·å–APIå¯†é’¥
    String apiKey = System.getenv("YOUR_API_KEY_ENV_VAR");  // ä¿®æ”¹ç¯å¢ƒå˜é‡å
    if (apiKey != null) {
        config.setOpenaiApiKey(apiKey);
    }
    
    // ç›´æ¥è®¾ç½®LLMé…ç½®
    config.setOpenaiApiUrl("https://your-llm-provider.com/v1/chat/completions");  // ä¿®æ”¹API URL
    config.setOpenaiModel("your-model-name");  // ä¿®æ”¹æ¨¡å‹åç§°
    
    // å¦‚æœéœ€è¦ä¿®æ”¹embeddingé…ç½®
    config.setEmbeddingApiUrl("https://your-embedding-provider.com/v1/embeddings");
    config.setEmbeddingModel("your-embedding-model");
    
    // Neo4jé…ç½®ï¼ˆå¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹ï¼‰
    config.setUri("bolt://localhost:7687");
    config.setUsername("neo4j");
    config.setPassword("password");
    
    return config;
}
```

### æ–¹æ³•3ï¼šé€šè¿‡ç¯å¢ƒå˜é‡ï¼ˆæœ€çµæ´»ï¼‰

#### è®¾ç½®ç¯å¢ƒå˜é‡
```bash
# Linux/Mac
export YOUR_API_KEY=your_actual_api_key
export LLM_BASE_URL=https://your-llm-provider.com/v1/chat/completions
export LLM_MODEL=your-model-name
export EMBEDDING_BASE_URL=https://your-embedding-provider.com/v1/embeddings
export EMBEDDING_MODEL=your-embedding-model

# Windows
set YOUR_API_KEY=your_actual_api_key
set LLM_BASE_URL=https://your-llm-provider.com/v1/chat/completions
set LLM_MODEL=your-model-name
set EMBEDDING_BASE_URL=https://your-embedding-provider.com/v1/embeddings
set EMBEDDING_MODEL=your-embedding-model
```

#### ä¿®æ”¹ä»£ç è¯»å–ç¯å¢ƒå˜é‡
```java
private static GraphConfig createConfig() {
    GraphConfig config = new GraphConfig();
    
    // ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
    String apiKey = System.getenv("YOUR_API_KEY");
    String baseUrl = System.getenv("LLM_BASE_URL");
    String model = System.getenv("LLM_MODEL");
    String embeddingUrl = System.getenv("EMBEDDING_BASE_URL");
    String embeddingModel = System.getenv("EMBEDDING_MODEL");
    
    if (apiKey != null) config.setOpenaiApiKey(apiKey);
    if (baseUrl != null) config.setOpenaiApiUrl(baseUrl);
    if (model != null) config.setOpenaiModel(model);
    if (embeddingUrl != null) config.setEmbeddingApiUrl(embeddingUrl);
    if (embeddingModel != null) config.setEmbeddingModel(embeddingModel);
    
    return config;
}
```

## ğŸ¯ å¸¸è§LLMä¾›åº”å•†é…ç½®ç¤ºä¾‹

### 1. ä½¿ç”¨OpenAIå…¼å®¹APIï¼ˆå¦‚vLLMã€Ollamaç­‰ï¼‰
```properties
openai.api.url=http://localhost:8000/v1/chat/completions
openai.model=llama-3.1-8b-instruct
```

### 2. ä½¿ç”¨Azure OpenAI
```properties
openai.api.url=https://your-resource.openai.azure.com/openai/deployments/your-deployment/chat/completions?api-version=2024-02-15-preview
openai.model=gpt-4
```

### 3. ä½¿ç”¨Anthropic Claudeï¼ˆéœ€è¦é€‚é…å™¨ï¼‰
```properties
openai.api.url=https://api.anthropic.com/v1/messages
openai.model=claude-3-sonnet-20240229
```

### 4. ä½¿ç”¨Google Geminiï¼ˆéœ€è¦é€‚é…å™¨ï¼‰
```properties
openai.api.url=https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent
openai.model=gemini-pro
```

### 5. ä½¿ç”¨æœ¬åœ°éƒ¨ç½²çš„æ¨¡å‹
```properties
openai.api.url=http://localhost:11434/v1/chat/completions
openai.model=llama3.1:8b
```

## ğŸ”§ é«˜çº§é…ç½®é€‰é¡¹

### æ¨ç†å‚æ•°è°ƒæ•´
```properties
# æ¨ç†æ·±åº¦ï¼ˆå›¾éå†çš„æœ€å¤§å±‚æ•°ï¼‰
reasoning.max.depth=3

# æœç´¢å®½åº¦ï¼ˆæ¯å±‚æ¢ç´¢çš„å®ä½“æ•°é‡ï¼‰
reasoning.width=5

# å®ä½“ç›¸ä¼¼åº¦é˜ˆå€¼
reasoning.entity.threshold=0.3

# å…³ç³»ç›¸ä¼¼åº¦é˜ˆå€¼
reasoning.relation.threshold=0.2

# LLMç”Ÿæˆå‚æ•°
reasoning.temperature=0.0
reasoning.max.tokens=512
```

### æ€§èƒ½ä¼˜åŒ–é…ç½®
```java
// åœ¨GraphConfigä¸­æ·»åŠ 
private int threadPoolSize = 4;           // å¹¶è¡Œå¤„ç†çº¿ç¨‹æ•°
private int batchSize = 10;               // æ‰¹å¤„ç†å¤§å°
private boolean enableCaching = true;     // å¯ç”¨ç¼“å­˜
private int cacheSize = 1000;             // ç¼“å­˜å¤§å°
private long requestTimeout = 30000;      // è¯·æ±‚è¶…æ—¶æ—¶é—´(ms)
```

## ğŸš€ å¿«é€Ÿé…ç½®è„šæœ¬

åˆ›å»ºä¸€ä¸ªé…ç½®è„šæœ¬ `configure-llm.sh`ï¼š
```bash
#!/bin/bash

echo "=== LLM Provider Configuration ==="

# è¯»å–ç”¨æˆ·è¾“å…¥
read -p "Enter your API key: " API_KEY
read -p "Enter base URL (e.g., https://api.openai.com/v1/chat/completions): " BASE_URL
read -p "Enter model name (e.g., gpt-3.5-turbo): " MODEL_NAME

# è®¾ç½®ç¯å¢ƒå˜é‡
export YOUR_API_KEY="$API_KEY"
export LLM_BASE_URL="$BASE_URL"
export LLM_MODEL="$MODEL_NAME"

echo "Configuration set!"
echo "API Key: $YOUR_API_KEY"
echo "Base URL: $LLM_BASE_URL"
echo "Model: $LLM_MODEL"

# è¿è¡Œæ¼”ç¤º
echo "Starting demo..."
mvn exec:java -Dexec.mainClass="com.tog.graph.demo.GraphReasoningDemo"
```

## ğŸ“ æ³¨æ„äº‹é¡¹

### 1. APIå…¼å®¹æ€§
- ç¡®ä¿ä½ çš„LLMä¾›åº”å•†æä¾›OpenAIå…¼å®¹çš„APIæ ¼å¼
- å¦‚æœä¸å…¼å®¹ï¼Œå¯èƒ½éœ€è¦ä¿®æ”¹ `OpenAIService.java` ä¸­çš„è¯·æ±‚æ ¼å¼

### 2. è®¤è¯æ–¹å¼
- ä¸åŒä¾›åº”å•†å¯èƒ½ä½¿ç”¨ä¸åŒçš„è®¤è¯æ–¹å¼ï¼ˆBearer tokenã€API keyç­‰ï¼‰
- å¯èƒ½éœ€è¦ä¿®æ”¹HTTPè¯·æ±‚å¤´çš„è®¾ç½®

### 3. å“åº”æ ¼å¼
- ç¡®ä¿å“åº”æ ¼å¼ä¸OpenAI APIå…¼å®¹
- ç‰¹åˆ«æ³¨æ„ `choices[0].message.content` å­—æ®µçš„è·¯å¾„

### 4. é”™è¯¯å¤„ç†
- ä¸åŒä¾›åº”å•†çš„é”™è¯¯ç å’Œé”™è¯¯ä¿¡æ¯æ ¼å¼å¯èƒ½ä¸åŒ
- å»ºè®®æµ‹è¯•é”™è¯¯å¤„ç†é€»è¾‘

## ğŸ§ª æµ‹è¯•é…ç½®

ä¿®æ”¹é…ç½®åï¼Œè¿è¡Œæµ‹è¯•ï¼š
```bash
# æµ‹è¯•åŸºæœ¬åŠŸèƒ½
./run-demo.sh

# æµ‹è¯•å¼‚æ­¥åŠŸèƒ½
./run-async-demo.sh

# æµ‹è¯•embeddingåŠŸèƒ½
./test-embedding.sh
```

è¿™æ ·ä½ å°±å¯ä»¥è½»æ¾åœ°åˆ‡æ¢åˆ°ä»»ä½•LLMä¾›åº”å•†äº†ï¼